{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dt_train1.txt', sep='\\t')\n",
    "test = pd.read_csv('dt_test1.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label, *_ = list(set(train.columns) - set(test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, labels = pd.concat([train, test]), dict()\n",
    "for column in df:\n",
    "    df[column], labels[column] = pd.factorize(df[column])\n",
    "    # labels[column] = labels[column].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.iloc[:len(train)].drop(y_label, axis=1)\n",
    "y_train = df.iloc[:len(train)][y_label]\n",
    "x_test = df.iloc[len(train):].drop(y_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, metric):\n",
    "        self.tree = None\n",
    "        self._metric = metric\n",
    "    \n",
    "    def _terminal(self, train):\n",
    "        return Counter(train[:, -1]).most_common()[0][0]\n",
    "    \n",
    "    def _build(self, train, depth=1):\n",
    "        # gini index\n",
    "        _metric = lambda groups: sum([(1.-sum([(v/len(g))**2 for k, v in Counter(g[:, -1]).items()])) * (len(g)/len(list(chain(*groups)))) for g in filter(np.any, groups)])\n",
    "        # split data where value lower than v and else\n",
    "        _split = lambda i, v: (train[np.where(train[:, i] < v)], train[np.where(train[:, i] >= v)])\n",
    "        # _split and calc value using _metric\n",
    "        _apply = np.vectorize(lambda v, i: _metric(_split(i, v)))\n",
    "        # get index of _applyed minimum\n",
    "        _mini = lambda uni, idx, i: idx[_apply(uni, i).argmin()]\n",
    "        \n",
    "        m = np.apply_along_axis(lambda i: _mini(*np.unique(train[:, i], return_index=True), i), 1, np.array([np.arange(self._c-1)]).T)\n",
    "        i, j = min(enumerate(m), key=lambda t: _metric(_split(t[0], train[t[1]][t[0]])))\n",
    "        l, r = _split(i, train[j][i])\n",
    "        \n",
    "        node = {\n",
    "            'index': i,\n",
    "            'value': train[j][i],\n",
    "            'left': l,\n",
    "            'right': r\n",
    "        }\n",
    "        \n",
    "        if not len(l) or not len(r):\n",
    "            node['left'] = node['right'] = self._terminal(np.concatenate([l, r]))\n",
    "        elif depth >= self.max_depth:\n",
    "            node['left'], node['right'] = self._terminal(l), self._terminal(r)\n",
    "        else:\n",
    "            node['left'] = self._terminal(l) if len(l) <= self.min_size else self._build(l, depth+1)\n",
    "            node['right'] = self._terminal(r) if len(r) <= self.min_size else self._build(r, depth+1)\n",
    "        return node\n",
    "    \n",
    "    def fit(self, X, y, max_depth=32, min_size=.0):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        \n",
    "        train = np.concatenate([X, np.array([y]).T], axis=1)\n",
    "        self._r, self._c = train.shape\n",
    "        self.tree = self._build(train)\n",
    "\n",
    "    def _predict(self, node, x):\n",
    "        tar = node['left'] if x[node['index']] < node['value'] else node['right']\n",
    "        return self._predict(tar, x) if isinstance(tar, dict) else tar\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.apply_along_axis(partial(self._predict, self.tree), 1, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTree(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(x_train, y_train, 16, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[y_label] = pd.Series(map(lambda y: labels[y_label][y], classifier.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('dt_result1.txt', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.read_csv('dt_answer1.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(326, 346)"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "sum(test[y_label] == answer[y_label]), len(test[y_label])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bit4b8c9347d4274ebcb4cd7470922341df"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}